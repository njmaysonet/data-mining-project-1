{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Project 1 - Report 1 code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please have the 'playlists4000.txt' file in the same directory as this notebook.\n",
    "\n",
    "fd = open(\"playlists4000.txt\",mode='r',encoding='utf8',newline='\\n')\n",
    "\n",
    "raw = fd.read().splitlines()\n",
    "\n",
    "hashtable = dict()\n",
    "\n",
    "for line in raw:\n",
    "    first, second = line.split(sep=\"::\")\n",
    "    hashtable.setdefault(first, []).append(second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hashtable.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Longest transaction\n",
    "longest = 0\n",
    "for x in hashtable.values():\n",
    "    if (len(x) > longest):\n",
    "        longest = len(x)\n",
    "\n",
    "longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shortest transaction\n",
    "shortest = longest\n",
    "for x in hashtable.values():\n",
    "    if(len(x) < shortest):\n",
    "        shortest = len(x)\n",
    "shortest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support counting\n",
    "\n",
    "#Dictionary of 1-itemsets with support count\n",
    "\n",
    "counts = dict()\n",
    "\n",
    "for line in raw:\n",
    "    first, second = line.split(sep=\"::\")\n",
    "    x = counts.setdefault(second,0)\n",
    "    counts[second] = x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(counts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of frequent 1-itemsets with support count threshold 400\n",
    "freq = 0\n",
    "\n",
    "for x in counts:\n",
    "    if(counts[x] > 40):\n",
    "        freq += 1\n",
    "\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Highest support for a 1-itemset\n",
    "max(counts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_counts = pd.DataFrame.from_dict(counts, orient='index')\n",
    "\n",
    "df_counts = df_counts.set_axis(['support'],axis=1)\n",
    "\n",
    "df_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = df_counts.loc[df_counts['support'] > 50]\n",
    "\n",
    "plot_df = plot_df.sort_values(by=['support']).reset_index()\n",
    "\n",
    "plot_df = plot_df.rename(columns={'index' : 'Items','support':'Support'})\n",
    "\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(num=1,figsize=(20,15), dpi=100)\n",
    "plt.bar(plot_df['Items'], plot_df['Support'])\n",
    "plt.xticks(np.arange(0, 333, 10))\n",
    "plt.xlabel('Item')\n",
    "plt.ylabel('Support')\n",
    "plt.title('Support counts in increasing order')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minsup, minconf = 5, 0.5\n",
    "minsup, minconf = 30, 0.7\n",
    "# minsup, minconf = 60, 0.5\n",
    "# minsup, minconf = 60, 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP-Tree generateion of 4-itemsets with support count and pruning\n",
    "from collections import OrderedDict\n",
    "fp = OrderedDict()\n",
    "\n",
    "# 1-itemset support counting\n",
    "for t in hashtable.values():\n",
    "    for ii in range(len(t)):\n",
    "        i = int(t[ii])\n",
    "        fp[i] = fp.get(i, OrderedDict())\n",
    "        fp[i][\"count\"] = fp[i].get(\"count\", 0) + 1\n",
    "\n",
    "# 2-itemset support counting\n",
    "for t in hashtable.values():\n",
    "    for ii in range(len(t)):\n",
    "        i = int(t[ii])\n",
    "        # if support count is too low\n",
    "        # prune 1-itemset\n",
    "        if i in fp and fp[i][\"count\"] < minsup:\n",
    "            continue\n",
    "        if i not in fp:\n",
    "            continue\n",
    "        for ji in range(ii+1, len(t)):\n",
    "            j = int(t[ji])\n",
    "            fp[i][j] = fp[i].get(j, OrderedDict())\n",
    "            fp[i][j][\"count\"] = fp[i][j].get(\"count\", 0) + 1\n",
    "\n",
    "# 3-itemset support counting            \n",
    "for t in hashtable.values():\n",
    "    for ii in range(len(t)):\n",
    "        i = int(t[ii])\n",
    "        # if fp[i][\"count\"] < minsup:\n",
    "        #     continue\n",
    "        if i not in fp:\n",
    "            continue\n",
    "        for ji in range(ii+1, len(t)):\n",
    "            j = int(t[ji])\n",
    "            # if support count is too low\n",
    "            # prune 2-itemset\n",
    "            if j in fp[i] and fp[i][j][\"count\"] < minsup:\n",
    "                del fp[i][j]\n",
    "                continue\n",
    "            if j not in fp[i]:\n",
    "                continue    \n",
    "            for ki in range(ji+1, len(t)):\n",
    "                k = int(t[ki])\n",
    "                fp[i][j][k] = fp[i][j].get(k, OrderedDict())\n",
    "                fp[i][j][k][\"count\"] = fp[i][j][k].get(\"count\", 0) + 1\n",
    "\n",
    "# 4-itemset support couting\n",
    "for t in hashtable.values():\n",
    "    for ii in range(len(t)):\n",
    "        i = int(t[ii])\n",
    "        # if fp[i][\"count\"] < minsup:\n",
    "        #     continue\n",
    "        if i not in fp:\n",
    "            continue\n",
    "        for ji in range(ii+1, len(t)):\n",
    "            j = int(t[ji])\n",
    "            # if fp[i][j][\"count\"] < minsup:\n",
    "            #     continue\n",
    "            if j not in fp[i]:\n",
    "                continue \n",
    "            for ki in range(ji+1, len(t)):\n",
    "                k = int(t[ki])\n",
    "                # if support count is too low\n",
    "                # prune 3-itemset\n",
    "                if k in fp[i][j] and fp[i][j][k][\"count\"] < minsup:\n",
    "                    del fp[i][j][k]\n",
    "                    continue\n",
    "                if k not in fp[i][j]:\n",
    "                    continue\n",
    "                for li in range(ki+1, len(t)):\n",
    "                    l = int(t[li])\n",
    "                    fp[i][j][k][l] = fp[i][j][k].get(l, OrderedDict())\n",
    "                    fp[i][j][k][l][\"count\"] = fp[i][j][k][l].get(\"count\", 0) + 1\n",
    "                \n",
    "ctr = 0\n",
    "for k, v in fp.items():\n",
    "    ctr += v[\"count\"]\n",
    "fp[\"count\"] = ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fp[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support counting\n",
    "\n",
    "# Dictionary of 1-itemsets, 2-itemsets, and 3-itemsets with support count\n",
    "\n",
    "itemsets = dict()\n",
    "itemsets[1] = OrderedDict()\n",
    "itemsets[2] = OrderedDict()\n",
    "itemsets[3] = OrderedDict()\n",
    "itemsets[4] = OrderedDict()\n",
    "\n",
    "def generate(node, s, len=0):\n",
    "    # Support count-based pruning\n",
    "    if \"count\" in node and node[\"count\"] < minsup:\n",
    "        return\n",
    "    if len >= 1:\n",
    "        itemset = tuple(sorted(s))\n",
    "        itemsets[len][itemset] = node[\"count\"]\n",
    "    if len == 4:\n",
    "        return\n",
    "    for k in node:\n",
    "        if k != \"count\":\n",
    "            generate(node[k], s + [int(k)], len+1)\n",
    "\n",
    "generate(fp, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule generation for 2-itemsets with minsup a and minconf b\n",
    "rules = dict()\n",
    "rules[2] = dict()\n",
    "rules[3] = dict()\n",
    "rules[2][\"antecedent\"] = list()\n",
    "rules[2][\"consequent\"] = list()\n",
    "rules[2][\"support count\"] = list()\n",
    "rules[2][\"confidence\"] = list()\n",
    "rules[3][\"antecedent\"] = list()\n",
    "rules[3][\"consequent\"] = list()\n",
    "rules[3][\"support count\"] = list()\n",
    "rules[3][\"confidence\"] = list()\n",
    "\n",
    "\n",
    "for k, v in itemsets[2].items():\n",
    "    # print(\", \".join(list(map(str, list(k)))), end=\"\\t\")\n",
    "    # print(\"count: \", str(v))\n",
    "    f, s = k\n",
    "    n, d = v, itemsets[1][tuple([f])]\n",
    "    conf = n / d\n",
    "    if conf >= minconf:\n",
    "        rules[2][\"antecedent\"].append(f)\n",
    "        rules[2][\"consequent\"].append(s)\n",
    "        rules[2][\"support count\"].append(n)\n",
    "        rules[2][\"confidence\"].append(round(conf, 4))\n",
    "        # rules[2][f\"{f} -> {s}\"] =  [round(conf, 4), n]\n",
    "    d = itemsets[1][tuple([s])]\n",
    "    conf = n / d\n",
    "    if conf >= minconf:\n",
    "        rules[2][\"antecedent\"].append(f)\n",
    "        rules[2][\"consequent\"].append(s)\n",
    "        rules[2][\"support count\"].append(n)\n",
    "        rules[2][\"confidence\"].append(round(conf, 4))\n",
    "        # rules[2][f\"{f} -> {s}\"] = [round(conf, 4), n]\n",
    "\n",
    "# for k, v in rules[2].items():\n",
    "#     print(k, end=\"\\t\\t\")\n",
    "#     print(\"support count: \", str(v[1]), end=\"\\t\\t\")\n",
    "#     print(\"confidence: \", str(v[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule generation for 3-itemsets with minsup a and minconf b\n",
    "\n",
    "seen = set()\n",
    "\n",
    "def rule_gen_3_2(three: tuple, prevant: tuple):\n",
    "    f, m, e = three\n",
    "    pf, ps = prevant\n",
    "    diff = list(set([f, m, e]).difference(set([pf, ps])))[0]\n",
    "    ant, cons =  tuple([pf]), tuple(sorted([ps, diff]))\n",
    "    n, d = itemsets[3][three], itemsets[1][ant]\n",
    "    conf = n / d\n",
    "    sant = \", \".join(list(map(str, list(ant))))\n",
    "    scons = \", \".join(list(map(str, list(cons))))\n",
    "    rulestr = f\"{sant}\\t--->\\t{scons}\"\n",
    "    if conf >= minconf and rulestr not in seen:\n",
    "        seen.add(rulestr)\n",
    "        rules[3][\"antecedent\"].append(sant)\n",
    "        rules[3][\"consequent\"].append(scons)\n",
    "        rules[3][\"support count\"].append(n)\n",
    "        rules[3][\"confidence\"].append(round(conf, 4))\n",
    "        # rules[3][rulestr] = [round(conf, 4), n]\n",
    "    ant, cons =  tuple([ps]), tuple(sorted([pf, diff]))\n",
    "    n, d = itemsets[3][three], itemsets[1][ant]\n",
    "    conf = n / d\n",
    "    sant = \", \".join(list(map(str, list(ant))))\n",
    "    scons = \", \".join(list(map(str, list(cons))))\n",
    "    rulestr = f\"{sant}\\t--->\\t{scons}\"\n",
    "    if conf >= minconf and rulestr not in seen:\n",
    "        seen.add(rulestr)\n",
    "        rules[3][\"antecedent\"].append(sant)\n",
    "        rules[3][\"consequent\"].append(scons)\n",
    "        rules[3][\"support count\"].append(n)\n",
    "        rules[3][\"confidence\"].append(round(conf, 4))\n",
    "        # rules[3][rulestr] = [round(conf, 4), n]\n",
    "    \n",
    "\n",
    "def rule_gen_3(three: tuple):\n",
    "    f, m, e = three\n",
    "    ant = tuple(sorted([m, e]))\n",
    "    cons  = tuple([f])\n",
    "    n, d = itemsets[3][three], itemsets[2][ant]\n",
    "    conf = n / d\n",
    "    sant = \", \".join(list(map(str, list(ant))))\n",
    "    scons = \", \".join(list(map(str, list(cons))))\n",
    "    rulestr = f\"{sant}\\t--->\\t{scons}\"\n",
    "    if conf >= minconf and rulestr not in seen:\n",
    "        rules[3][\"antecedent\"].append(sant)\n",
    "        rules[3][\"consequent\"].append(scons)\n",
    "        rules[3][\"support count\"].append(n)\n",
    "        rules[3][\"confidence\"].append(round(conf, 4))\n",
    "        # rules[3][f\"{sant}\\t--->\\t{scons}\"] = [round(conf, 4), n]\n",
    "        rule_gen_3_2(three, ant)\n",
    "    ant, cons = tuple(sorted([f, e])), tuple([m])\n",
    "    n, d = itemsets[3][three], itemsets[2][ant]\n",
    "    conf = n / d\n",
    "    sant = \", \".join(list(map(str, list(ant))))\n",
    "    scons = \", \".join(list(map(str, list(cons))))\n",
    "    rulestr = f\"{sant}\\t--->\\t{scons}\"\n",
    "    if conf >= minconf and rulestr not in seen:\n",
    "        rules[3][\"antecedent\"].append(sant)\n",
    "        rules[3][\"consequent\"].append(scons)\n",
    "        rules[3][\"support count\"].append(n)\n",
    "        rules[3][\"confidence\"].append(round(conf, 4))\n",
    "        # rules[3][f\"{sant}\\t--->\\t{scons}\"] = [round(conf, 4), n]\n",
    "        rule_gen_3_2(three, ant)\n",
    "    ant, cons = tuple(sorted([f, m])), tuple([e])\n",
    "    n, d = itemsets[3][three], itemsets[2][ant]\n",
    "    conf = n / d\n",
    "    if conf >= minconf:\n",
    "        sant = \", \".join(list(map(str, list(ant))))\n",
    "        scons = \", \".join(list(map(str, list(cons))))\n",
    "        rules[3][\"antecedent\"].append(sant)\n",
    "        rules[3][\"consequent\"].append(scons)\n",
    "        rules[3][\"support count\"].append(n)\n",
    "        rules[3][\"confidence\"].append(round(conf, 4))\n",
    "        # rules[3][f\"{sant}\\t--->\\t{scons}\"] = [round(conf, 4), n]\n",
    "        rule_gen_3_2(three, ant)\n",
    "    \n",
    "    \n",
    "for k, v in itemsets[3].items(): \n",
    "    rule_gen_3(k)\n",
    "\n",
    "# for k, v in rules[3].items():\n",
    "#     print(k, end=\"\\t\\t\")\n",
    "#     print(\"support count: \", str(v[1]), end=\"\\t\\t\")\n",
    "#     print(\"confidence: \", str(v[0]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe for 2-itemset rules\n",
    "import pandas as pd\n",
    "\n",
    "two_itemset_rules = pd.DataFrame(rules[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_itemset_rules.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe for 3-itemset rules\n",
    "import pandas as pd\n",
    "\n",
    "three_itemset_rules = pd.DataFrame(rules[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_itemset_rules.head(10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72b85386bb70c73d583304b77bf343b8ae28fafa227bccfdb99caed8a25c4bce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
